{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb67a2c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier For Spam Emails\n",
    "\n",
    "This notebook outlines the usage of the random forest classifier model for the purpose of classifying spam emails. I chose the rfc model for the following reasons: it is highly robust due to the number of decision trees, it does not suffer from overfitting as a result of the averages which removes bias, it can handle missing values using either median values or proximity-weighted averages, and the relative feature importance is easily accessible. However, the random forests method is slower than others because of the necessity of creating multiple decision trees. For each prediction, each tree will have to make a prediction and then the model will need to vote. Moreover, the model can be more difficult to interpret as compared to a regular decision tree since it cannot be followed along a singular path. Despite the issues of the random forests model, the benefits seem to outweigh the problems and so it is likely the best option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9b711",
   "metadata": {},
   "source": [
    "First, let's install some stuff just in case you don't already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "307b9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e16fe",
   "metadata": {},
   "source": [
    "Some imports to help us moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be78e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c7515",
   "metadata": {},
   "source": [
    "Now we can read from the files in order to create the dataframe. Then we split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "613e69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the names for the columns\n",
    "with open('spambase/spambase.names') as fp:\n",
    "    cols = []\n",
    "    for line in fp:\n",
    "        # ignore the documentation lines\n",
    "        if line.startswith('|'):\n",
    "            continue\n",
    "        # essentially matches lines that go \"foo_bar: foo bar.\"\n",
    "        # colname = foo_bar\n",
    "        regexer = re.match(r'(?P<colname>.+):.*\\.', line)\n",
    "        # add colname to the list of columns\n",
    "        if regexer:\n",
    "            cols.append(regexer.group('colname'))\n",
    "    # append the label to the list of columns\n",
    "    cols.append('label')\n",
    "\n",
    "# now we can create the dataframe, this will contain all of the data\n",
    "options = {'header': None, 'names': cols, 'skipinitialspace': True}\n",
    "spambase = pd.read_csv('spambase/spambase.data', **options)\n",
    "\n",
    "# split the dataframe into predictors and labels\n",
    "x_spambase = spambase.drop(['label'], axis=1)\n",
    "y_spambase = spambase['label']\n",
    "\n",
    "# finally, split that result into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_spambase, y_spambase, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "babfbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the classifier\n",
    "mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "\n",
    "# fit the training data to the model\n",
    "mdl.fit(x_train, y_train)\n",
    "\n",
    "# run the prediction to check accuracy\n",
    "y_pred = mdl.predict(x_test)\n",
    "\n",
    "# calculate the accuracy and baseline scores\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "scores = classification_report(y_test, y_pred, output_dict=True)['weighted avg']\n",
    "\n",
    "accuracy_info = f'''Test accuracy score: {accuracy}%\n",
    "    Precision: {scores['precision']}\n",
    "    Recall:    {scores['recall']}\n",
    "    F1-Score:  {scores['f1-score']}\n",
    "    Support:   {scores['support']}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "29f8e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score: 95.55%\n",
      "    Precision: 0.9557319058313629\n",
      "    Recall:    0.9554831704668838\n",
      "    F1-Score:  0.9552578185687747\n",
      "    Support:   921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
